<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Zijie Li</title>

    <meta name="author" content="Jon Barron">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;
    margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Zijie Li
                </p>
                <p>Welcome! I'm a PhD candiate at <a href="https://sites.google.com/view/barati">Mechanical and AI lab</a> in Mechanical Engineering department at CMU,
                   where I works at the intersection of numerical phyiscs simulation and deep learning. I also spent a summer in Tiktok Seed-Image-Generation department,
                   doing research on text/image generation with diffusion model.
                  </p>
                   <p>
                   <strong>(I will be graduating around 2025 March. If you think I am a good fit for your position, please feel free to reach out)</strong>
                </p>
                <p style="text-align:center">
                  <a href="mailto:zijieli@andrew.cmu.edu">Email</a> &nbsp;/&nbsp;
                  <a href="data/Zijie_CV_2024_Nov.pdf">CV (last update Nov 2024)</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=ji7TXTMAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/zijieli-Jlee/">Github</a>  &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/zijie-li-827976103/">Linkedin</a>

                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/Perosnal figure.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/Perosnal figure.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;margin-bottom:0px;margin-top:0px;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I'm interested in deep learning for physics simulation spans from particle-based dynamics to Eulerian fluid simulation. In particular, how can we tweak popular
                popular neural network architecture such as graph neural network and Transformer using the insights and lessons from numerical solvers to make them better suited for specific simulation tasks.
                Recently I've been working on diffusion models for both physics prediction and its applications to different modalities (e.g. text).
              </span> 
              </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;margin-bottom:0px;margin-top:0px;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle;">
              <h2>Selected Publications</h2><p>
                (* denotes equal contribution)
              </p>
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle;">
              <h3>Preprint</h3>
            </td>
          </tr>
        </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;margin-bottom:0px;margin-top:0px;"><tbody>
          <td style="padding:20px;width:30%;vertical-align:middle"><img src="images/cafa_prediction.gif" width="400" height="140"></td>
          <td width="70%" valign="middle">
            <a href="https://arxiv.org/abs/2405.07395">
              <span class="papertitle">CaFA: Global Weather Forecasting with Factorized Attention on Sphere
              </span>
            </a>
            <br>
          <strong>Zijie Li</strong>,
          Anthony Zhou,
          Saurabh Patil,
          Amir Barati Farimani,

            <br>
            <em>In submission<em>, 2024
            <br>
            <a href="https://github.com/BaratiLab/CaFA">code</a>
            <br>
            <p>
            A lightweight Transformer with axial factorized attention designed for sphere. 
            The model achieves comparable medium-range forecast accuracy compared to several other state-of-the-art Transformer model with greatly reduced compute.
            </p>
          </td>
        </tr>
      </tbody></table>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;margin-bottom:0px;margin-top:0px;"><tbody>

        <td style="padding:20px;width:100%;vertical-align:middle">

          <h3>Peer-reviewed</h3>
        </td>
      </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:10px;width:30%;vertical-align:middle"><img src="images/FactFormer-Schematic.png" width="400" height="96"></td>
            <td width="70%" valign="middle">
              <a href="https://arxiv.org/abs/2305.17560">
                <span class="papertitle">Scalable Transformer for PDE Surrogate Modeling</span>
              </a>
              <br>
            <strong>Zijie Li</strong>,
            Dule Shu,
            Amir Barati Farimani,

              <br>
              <em>NeurIPS poster<em>, 2023
              <br>
              <a href="https://github.com/BaratiLab/FactFormer">code</a>
              <br>
              <p>
              In this paper we propose a axial factorized attention scheme to improve 
              the scalability of Transformer on multi-dimensional PDE problems.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:30%;vertical-align:middle"><img src="images/Schematic-OFormer.png" width="400" height="192"></td>
            <td width="70%" valign="middle">
              <a href="https://openreview.net/forum?id=EPPqt3uERT&referrer=%5BTMLR%5D(%2Fgroup%3Fid%3DTMLR)">
                <span class="papertitle">Transformer for Partial Differential Equationsâ€™ Operator Learning                </span>
              </a>
              <br>
            <strong>Zijie Li</strong>,
            Kazem Meidani,
            Amir Barati Farimani,

              <br>
              <em>Transaction on Machine Learning Research
              <br>
              <a href="https://github.com/BaratiLab/OFormer">code</a>
              <br>
              <p>
              In this paper we propose and study a Transformer encoder-decoder structure that is capable of adapting to different types of discretization.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:30%;vertical-align:middle"><img src="images/diffusion_sample.gif" width="380" height="130"></td>
            <td width="70%" valign="middle">
              <a href="https://www.sciencedirect.com/science/article/pii/S0021999123000670">
                <span class="papertitle">A physics-informed diffusion model for high-fidelity flow field reconstruction  </span>
              </a>
              <br>
            Dule Shu*,
            <strong>Zijie Li*</strong>,
            Amir Barati Farimani,

              <br>
              <em>Journal of Computational Physics
              <br>
              <a href="https://github.com/BaratiLab/Diffusion-based-Fluid-Super-resolution">code</a>
              <br>
              <p>
              We investigate the use of diffusion model for high-fidelity flow field reconstruction. We also propose to incoorprate residual information into the backward diffusion process.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding-left:60px;padding-right:50px;width:30%;vertical-align:middle"><img src="images/project_moca.png" width="280" height="200"></td>
            <td width="70%" valign="middle">
              <a href="https://openreview.net/pdf?id=lY0-7bj0Vfz">
                <span class="papertitle">Prototype memory and attention mechanism for few-shot image generation </span>
              </a>
              <br>
              Tianqin Li*, <strong>Zijie Li*</strong>, Andrew Luo, Harold Rockwell, Amir Barati Farimani, Tai Sing Lee.

              <br>
              <em>ICLR poster, 2022
              <br>
              <a href="https://github.com/Crazy-Jack/MoCA_release">code</a>
              <br>
              <p>
              We propose an memory mechanism to augment the few-shot image generation task, where internal feature maps inside the Generator are modulated by attending with feature vectors stored in the memory bank.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding-left:50px;padding-right:50px;width:30%;vertical-align:middle"><img src="images/project_TPUGAN.png" width="280" height="200"></td>
            <td width="70%" valign="middle">
              <a href="https://openreview.net/forum?id=FEBFJ98FKx">
                <span class="papertitle">TPU-GAN: Learning temporal coherence from dynamic point cloud sequences  </span>
              </a>
              <br>
              <strong>Zijie Li</strong>, Tianqin Li, Amir Barati Farimani.

              <br>
              <em>ICLR poster, 2022
              <br>
              <a href="https://github.com/zijieli-Jlee/Temporal-Pointcloud-Upsampling-GAN">code</a>
              <br>
              <p>
                We propose a point cloud GAN architecture to learn the temporal coherence from dynamic point cloud sequences, which is capable of generating coherent point cloud motion.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding-left:70px;padding-right:50px;width:30%;vertical-align:middle"><img src="images/GAMD-banner.jpg" width="240" height="180"></td>
            <td width="70%" valign="middle">
              <a href="https://pubs.aip.org/aip/jcp/article-abstract/156/14/144103/2840972/Graph-neural-networks-accelerated-molecular?redirectedFrom=fulltext">
                <span class="papertitle">Graph neural networks accelerated molecular dynamics  </span>
              </a>
              <br>
              <strong>Zijie Li</strong>, Kazem Meidani, Prakarsh Yadav, Amir Barati Farimani.

              <br>
              <em>Journal of Chemical Physics, 2022
              <br>
              <a href="https://github.com/BaratiLab/GAMD">code</a>
              <br>
              <p>
                In this paper we study using graph neural network to directly model the atomic forces in molecular dynamics simulation.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding-left:120px;padding-right:120px;width:30%;vertical-align:middle"><img src="images/fgn-video.gif" width="150" height="180"></td>
            <td width="70%" valign="middle">
              <a href="https://www.sciencedirect.com/science/article/pii/S0097849322000206">
                <span class="papertitle">Graph neural network-accelerated Lagrangian fluid simulation  </span>
              </a>
              <br>
              <strong>Zijie Li</strong>, Amir Barati Farimani.

              <br>
              <em>Computers & Graphics, 2022
              <br>
              <a href="https://github.com/BaratiLab/FGN">code</a>
              <br>
              <p>
                In this paper we study using graph neural network to surrogate different components in a typical Lagrangian fluid simulation - advection and pressure projection.
              </p>
            </td>
          </tr>
        </tbody></table>

          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h2>Service</h2>
              <h3>Journal reviewer</h3>
              <p>
                Nature Machine Intelligence, IEEE Transactions on Neural Networks and Learning Systems, Transactions on Machine Learning Research
              </p>
              <h3>Conference reviewer</h3>
              <p>
                NeurIPS, ICLR
              </p>
            </td>
          </tr>
        </tbody></table>



        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Feel free to steal this website's <a href="https://github.com/jonbarron/jonbarron_website">source code</a>. <strong>Do not</strong> scrape the HTML from this page itself, as it includes analytics tags that you do not want on your own website &mdash; use the github code instead. Also, consider using <a href="https://leonidk.com/">Leonid Keselman</a>'s <a href="https://github.com/leonidk/new_website">Jekyll fork</a> of this page.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </tbody></table>
</body>
</html>
